{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"english_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMNiKO3ysl2vztFPv1rIjE7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7bf27f98109643569ac75f24a6753a62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_476c530515f14c84ae98ba155e976edc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_134c8ba5dcf848c9a639a20c499c3525","IPY_MODEL_526cde39bfae49388e4cf1888d0d8ee7"]}},"476c530515f14c84ae98ba155e976edc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"134c8ba5dcf848c9a639a20c499c3525":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8e34c98a0fbc4aae9d7c025d8aa1edf6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_369d488455bc4b0a8ecd276211fb266b"}},"526cde39bfae49388e4cf1888d0d8ee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70f41b5adc614fc2a1999c0cb49fe20b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.13MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80582531f8ce42709704eca87564481b"}},"8e34c98a0fbc4aae9d7c025d8aa1edf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"369d488455bc4b0a8ecd276211fb266b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70f41b5adc614fc2a1999c0cb49fe20b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80582531f8ce42709704eca87564481b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc3a6dc9527c4c29be13dfbcc907a3b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7290205252cd40179e112c4247f5b3e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_542c26e013c74f28add9f8c4a0734394","IPY_MODEL_d82a155c6c1746f7a25eafdb1c6ad962"]}},"7290205252cd40179e112c4247f5b3e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"542c26e013c74f28add9f8c4a0734394":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b9bae6de186a486ca6b22fe8ba93e4fa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd88968455244921a89dd19ebaeb9a69"}},"d82a155c6c1746f7a25eafdb1c6ad962":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_566afb11601f4456a31a1da582eb5966","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 7.44kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_002fc0cb2356478a8e985169c279cb68"}},"b9bae6de186a486ca6b22fe8ba93e4fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd88968455244921a89dd19ebaeb9a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"566afb11601f4456a31a1da582eb5966":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"002fc0cb2356478a8e985169c279cb68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d97ebca0b754f0f973f3f9aa20d3398":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e57c6dab6c294d9ca1b7bc1de831e29d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9bf28ed1172c4293ae8278d835eac82c","IPY_MODEL_4e909617399444fa92d502df7be7e293"]}},"e57c6dab6c294d9ca1b7bc1de831e29d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bf28ed1172c4293ae8278d835eac82c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72c5a2819efb440895be1e4f5eba39e5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_036d405d69364ff9af5a977b19bba30f"}},"4e909617399444fa92d502df7be7e293":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7cbb2fa4f52463282ecaf3a67edc767","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:05&lt;00:00, 73.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b8453c0afde473cb05622d4f77f82cd"}},"72c5a2819efb440895be1e4f5eba39e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"036d405d69364ff9af5a977b19bba30f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7cbb2fa4f52463282ecaf3a67edc767":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b8453c0afde473cb05622d4f77f82cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"ymHJdofn5MSB","executionInfo":{"status":"ok","timestamp":1608625062325,"user_tz":-540,"elapsed":2002,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["from tensorflow.keras.models import Sequential, Model\r\n","from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense, Input, Flatten, Concatenate\r\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n","from tensorflow.keras.models import load_model"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BwA002kL5TtM","executionInfo":{"status":"ok","timestamp":1608625062327,"user_tz":-540,"elapsed":1355,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","import re\r\n","import urllib.request\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4qKCXae5fxy","executionInfo":{"status":"ok","timestamp":1608625074985,"user_tz":-540,"elapsed":13273,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"f1503d48-057e-4de6-c4f1-53b7119d6186"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1ifN5NrHZrEr"},"source":["### **훈련**\r\n","\r\n","훈련 파일 friends_train, frineds_test, friends_dev 파일을 불러옴"]},{"cell_type":"code","metadata":{"id":"2f9j1xR45jw_","executionInfo":{"status":"ok","timestamp":1608625077343,"user_tz":-540,"elapsed":2350,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["import json\r\n","\r\n","#txt2 = pd.read_csv('friends_train.json',sep='\\t')\r\n","with open('/content/drive/MyDrive/dataset/friends_train.json') as f:\r\n","    txt2 = json.load(f)\r\n","with open('/content/drive/MyDrive/dataset/friends_test.json') as f:\r\n","    txt3 = json.load(f)\r\n","with open('/content/drive/MyDrive/dataset/friends_dev.json') as f:\r\n","    txt4 = json.load(f)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAB3G_n45TvY","executionInfo":{"status":"ok","timestamp":1608625077612,"user_tz":-540,"elapsed":661,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["data = {\r\n","    'text' :[],\r\n","    'label': [],\r\n","}\r\n","#neutral joy sadness fear anger suprise disgust non\r\n","for n in txt2:\r\n","    for di in n:\r\n","        data['text'].append(di['utterance'])\r\n","        emotion = di['emotion']\r\n","        if emotion == 'neutral': emotion = 0\r\n","        elif emotion == 'joy': emotion = 1\r\n","        elif emotion == 'sadness': emotion = 2\r\n","        elif emotion == 'fear': emotion = 3\r\n","        elif emotion == 'anger': emotion = 4\r\n","        elif emotion == 'suprise': emotion = 5\r\n","        elif emotion == 'disgust': emotion = 6\r\n","        else: emotion = 7\r\n","        data['label'].append(emotion)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZP7rIJ05Txu","executionInfo":{"status":"ok","timestamp":1608625079229,"user_tz":-540,"elapsed":862,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_train = pd.DataFrame(data)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEnnZqdT5zGu","executionInfo":{"status":"ok","timestamp":1608625079488,"user_tz":-540,"elapsed":672,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["test_data = {\r\n","    'text' :[],\r\n","    'label': [],\r\n","}\r\n","#neutral joy sadness fear anger suprise disgust non\r\n","for n in txt3:\r\n","    for di in n:\r\n","        test_data['text'].append(di['utterance'])\r\n","        emotion = di['emotion']\r\n","        if emotion == 'neutral': emotion = 0\r\n","        elif emotion == 'joy': emotion = 1\r\n","        elif emotion == 'sadness': emotion = 2\r\n","        elif emotion == 'fear': emotion = 3\r\n","        elif emotion == 'anger': emotion = 4\r\n","        elif emotion == 'suprise': emotion = 5\r\n","        elif emotion == 'disgust': emotion = 6\r\n","        else: emotion = 7\r\n","        test_data['label'].append(emotion)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLFbYmo65zIz","executionInfo":{"status":"ok","timestamp":1608625080463,"user_tz":-540,"elapsed":513,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_test = pd.DataFrame(test_data)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIEAbd-dySpb","executionInfo":{"status":"ok","timestamp":1608625081962,"user_tz":-540,"elapsed":661,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["dev_data = {\r\n","    'text' :[],\r\n","    'label': [],\r\n","}\r\n","#neutral joy sadness fear anger suprise disgust non\r\n","for n in txt4:\r\n","    for di in n:\r\n","        dev_data['text'].append(di['utterance'])\r\n","        emotion = di['emotion']\r\n","        if emotion == 'neutral': emotion = 0\r\n","        elif emotion == 'joy': emotion = 1\r\n","        elif emotion == 'sadness': emotion = 2\r\n","        elif emotion == 'fear': emotion = 3\r\n","        elif emotion == 'anger': emotion = 4\r\n","        elif emotion == 'suprise': emotion = 5\r\n","        elif emotion == 'disgust': emotion = 6\r\n","        else: emotion = 7\r\n","        dev_data['label'].append(emotion)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtwZwAr_yaZ4","executionInfo":{"status":"ok","timestamp":1608625083299,"user_tz":-540,"elapsed":580,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_dev = pd.DataFrame(dev_data)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7yqZotvyd3h","executionInfo":{"status":"ok","timestamp":1608625083763,"user_tz":-540,"elapsed":545,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_train = pd.concat([ratings_train, ratings_dev])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRvnUiGt5Tz7","executionInfo":{"status":"ok","timestamp":1608625084084,"user_tz":-540,"elapsed":491,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"e5a9c6cc-3cb8-4db8-ebee-9adfcfdd109e"},"source":["ratings_train['text'].nunique(), ratings_train['label'].nunique()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10294, 7)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Z5PCUZ335T2M","executionInfo":{"status":"ok","timestamp":1608625085032,"user_tz":-540,"elapsed":562,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_train.drop_duplicates(subset=['text'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiTgaNPJ6GCp","executionInfo":{"status":"ok","timestamp":1608625086427,"user_tz":-540,"elapsed":1555,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["ratings_test.drop_duplicates(subset=['text'], inplace=True)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H-IHlc_5-7I","executionInfo":{"status":"ok","timestamp":1608625086427,"user_tz":-540,"elapsed":1073,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"148bc9ee-c5ea-4b49-8eaa-9aa02ee8eb40"},"source":["print('중복제거 후 학습데이터 : '+str(len(ratings_train)))\r\n","print('중복제거 후 테스트데이터: '+str(len(ratings_test)))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["중복제거 후 학습데이터 : 10294\n","중복제거 후 테스트데이터: 2505\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xo9Mdq0b5-9F","executionInfo":{"status":"ok","timestamp":1608625086850,"user_tz":-540,"elapsed":839,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["sentences = ratings_train.text.values\r\n","labels = ratings_train.label.values"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XbhQPbwU6R7l","executionInfo":{"status":"ok","timestamp":1608625092881,"user_tz":-540,"elapsed":6477,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"817a7fab-b719-436c-a113-4d557cef13c4"},"source":["!pip install transformers"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 16.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 43.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 54.4MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=2f514c9e3be4a3f1c37b91180a1e76bb7099828cd55bcc0260f7198f766d9c57\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["7bf27f98109643569ac75f24a6753a62","476c530515f14c84ae98ba155e976edc","134c8ba5dcf848c9a639a20c499c3525","526cde39bfae49388e4cf1888d0d8ee7","8e34c98a0fbc4aae9d7c025d8aa1edf6","369d488455bc4b0a8ecd276211fb266b","70f41b5adc614fc2a1999c0cb49fe20b","80582531f8ce42709704eca87564481b"]},"id":"EQUHaxoV5-_K","executionInfo":{"status":"ok","timestamp":1608625097614,"user_tz":-540,"elapsed":9266,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"90b22c72-a837-4d44-9b0b-1f0328209c34"},"source":["from transformers import BertTokenizer\r\n","\r\n","# Load the BERT tokenizer.\r\n","print('Loading BERT tokenizer...')\r\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bf27f98109643569ac75f24a6753a62","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO_RZK576VQM","executionInfo":{"status":"ok","timestamp":1608625100358,"user_tz":-540,"elapsed":10351,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"8c2db24f-a084-4b82-846e-94e9cfadd044"},"source":["max_len = 0\r\n","\r\n","for sent in sentences:\r\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\r\n","    max_len = max(max_len, len(input_ids))\r\n","\r\n","print('Max sentence length: ', max_len)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Max sentence length:  95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXBTSxA86Yi9","executionInfo":{"status":"ok","timestamp":1608625103853,"user_tz":-540,"elapsed":12975,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"04a27c97-6660-4640-c1cd-11298f7adf98"},"source":["import torch\r\n","\r\n","input_ids = []\r\n","attention_masks = []\r\n","\r\n","\r\n","for sent in sentences:\r\n","    encoded_dict = tokenizer.encode_plus(\r\n","                        sent,                      \r\n","                        add_special_tokens = True, \r\n","                        max_length = 64,        \r\n","                        pad_to_max_length = True,\r\n","                        return_attention_mask = True,  \r\n","                        return_tensors = 'pt', \r\n","                   )\r\n","    input_ids.append(encoded_dict['input_ids'])\r\n","    attention_masks.append(encoded_dict['attention_mask'])\r\n","\r\n","input_ids = torch.cat(input_ids, dim=0)\r\n","attention_masks = torch.cat(attention_masks, dim=0)\r\n","labels = torch.tensor(labels)\r\n","\r\n","print(sentences[0])\r\n","print(input_ids[0])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["also I was the point person on my companys transition from the KL-5 to GR-6 system.\n","tensor([  101,  2036,  1045,  2001,  1996,  2391,  2711,  2006,  2026,  2194,\n","         2015,  6653,  2013,  1996,  1047,  2140,  1011,  1019,  2000, 24665,\n","         1011,  1020,  2291,  1012,   102,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUtEVoSu6YlB","executionInfo":{"status":"ok","timestamp":1608625103855,"user_tz":-540,"elapsed":11410,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"c69999d5-cdb2-4699-bd39-2f86e51c2cbe"},"source":["from torch.utils.data import TensorDataset, random_split\r\n","\r\n","dataset = TensorDataset(input_ids, attention_masks, labels)\r\n","\r\n","train_size = int(0.9 * len(dataset))\r\n","val_size = len(dataset) - train_size\r\n","\r\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n","\r\n","print('{:>5,} training samples'.format(train_size))\r\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["9,264 training samples\n","1,030 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EAKkSHP46YnX","executionInfo":{"status":"ok","timestamp":1608625103856,"user_tz":-540,"elapsed":10104,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","batch_size = 256\r\n","\r\n","train_dataloader = DataLoader(\r\n","            train_dataset, \r\n","            sampler = RandomSampler(train_dataset), \r\n","            batch_size = batch_size \r\n","        )\r\n","\r\n","validation_dataloader = DataLoader(\r\n","            val_dataset,\r\n","            sampler = SequentialSampler(val_dataset),\r\n","            batch_size = batch_size \r\n","        )"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-2jR7yxFuhm","executionInfo":{"status":"ok","timestamp":1608625103857,"user_tz":-540,"elapsed":9231,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["if torch.cuda.is_available():\r\n","  device = torch.device('cuda')\r\n","else:\r\n","  device = torch.device('cpu')"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bc3a6dc9527c4c29be13dfbcc907a3b7","7290205252cd40179e112c4247f5b3e5","542c26e013c74f28add9f8c4a0734394","d82a155c6c1746f7a25eafdb1c6ad962","b9bae6de186a486ca6b22fe8ba93e4fa","cd88968455244921a89dd19ebaeb9a69","566afb11601f4456a31a1da582eb5966","002fc0cb2356478a8e985169c279cb68","5d97ebca0b754f0f973f3f9aa20d3398","e57c6dab6c294d9ca1b7bc1de831e29d","9bf28ed1172c4293ae8278d835eac82c","4e909617399444fa92d502df7be7e293","72c5a2819efb440895be1e4f5eba39e5","036d405d69364ff9af5a977b19bba30f","d7cbb2fa4f52463282ecaf3a67edc767","2b8453c0afde473cb05622d4f77f82cd"]},"id":"IDgvgztk6Ypb","executionInfo":{"status":"ok","timestamp":1608625123891,"user_tz":-540,"elapsed":27667,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"fe6ec323-ee4d-4b50-eb75-dac3aa9d8a53"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n","\r\n","model = BertForSequenceClassification.from_pretrained(\r\n","    \"bert-base-uncased\", \r\n","    num_labels = 8,\r\n","    output_attentions = False, \r\n","    output_hidden_states = False\r\n",")\r\n","model.cuda()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc3a6dc9527c4c29be13dfbcc907a3b7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d97ebca0b754f0f973f3f9aa20d3398","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"BpP0no9J6tDk","executionInfo":{"status":"ok","timestamp":1608625123892,"user_tz":-540,"elapsed":25443,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["optimizer = AdamW(model.parameters(),\r\n","                  lr = 2e-5,\r\n","                  eps = 1e-8 \r\n","                )"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"uozJ138b6tHT","executionInfo":{"status":"ok","timestamp":1608625123892,"user_tz":-540,"elapsed":24735,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["from transformers import get_linear_schedule_with_warmup\r\n","\r\n","epochs = 5\r\n","total_steps = len(train_dataloader) * epochs\r\n","scheduler = get_linear_schedule_with_warmup(optimizer, \r\n","                                            num_warmup_steps = 0, \r\n","                                            num_training_steps = total_steps)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDVuksCi6tJV","executionInfo":{"status":"ok","timestamp":1608625123892,"user_tz":-540,"elapsed":24125,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["import numpy as np\r\n","\r\n","def flat_accuracy(preds, labels):\r\n","    pred_flat = np.argmax(preds, axis=1).flatten()\r\n","    labels_flat = labels.flatten()\r\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLdbectv6tL7","executionInfo":{"status":"ok","timestamp":1608625123893,"user_tz":-540,"elapsed":23321,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["import time\r\n","import datetime\r\n","\r\n","def format_time(elapsed):\r\n","    elapsed_rounded = int(round((elapsed)))\r\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tKn-ZbE6tOh","executionInfo":{"status":"ok","timestamp":1608625606029,"user_tz":-540,"elapsed":482127,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"d805025d-f2a1-4bdf-97d9-02d63ae4389a"},"source":["import random\r\n","import numpy as np\r\n","\r\n","seed_val = 21\r\n","\r\n","random.seed(seed_val)\r\n","np.random.seed(seed_val)\r\n","torch.manual_seed(seed_val)\r\n","torch.cuda.manual_seed_all(seed_val)\r\n","training_stats = []\r\n","\r\n","\r\n","total_t0 = time.time()\r\n","\r\n","# For each epoch...\r\n","for epoch_i in range(0, epochs):\r\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n","\r\n","    t0 = time.time()\r\n","\r\n","    total_train_loss = 0\r\n","\r\n","    model.train()\r\n","\r\n","    for step, batch in enumerate(train_dataloader):\r\n","\r\n","        if step % 40 == 0 and not step == 0:\r\n","            elapsed = format_time(time.time() - t0)\r\n","\r\n","        b_input_ids = batch[0].to(device)\r\n","        b_input_mask = batch[1].to(device)\r\n","        b_labels = batch[2].to(device)\r\n","        model.zero_grad()        \r\n","        #batch = tuple(b.to(device) for b in batch)\r\n","        #b_input_ids, b_input_mask, b_labels = batch\r\n","\r\n","        outputs = model(b_input_ids, \r\n","                             token_type_ids=None, \r\n","                             attention_mask=b_input_mask, \r\n","                             labels=b_labels)\r\n","        loss=outputs[0]\r\n","\r\n","        total_train_loss += loss.item()\r\n","        loss.backward()\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","        optimizer.step()\r\n","        scheduler.step()\r\n","\r\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \r\n","    \r\n","    training_time = format_time(time.time() - t0)\r\n","\r\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n","    print(\"  Training epcoh took: {:}\".format(training_time))\r\n","\r\n","    t0 = time.time()\r\n","\r\n","    model.eval()\r\n","\r\n","\r\n","    total_eval_accuracy = 0\r\n","    total_eval_loss = 0\r\n","    nb_eval_steps = 0\r\n","\r\n","    for batch in validation_dataloader:\r\n","        b_input_ids = batch[0].to(device)\r\n","        b_input_mask = batch[1].to(device)\r\n","        b_labels = batch[2].to(device)\r\n","        \r\n","        with torch.no_grad():        \r\n","            outputs = model(b_input_ids, \r\n","                                   token_type_ids=None, \r\n","                                   attention_mask=b_input_mask,\r\n","                                   labels=b_labels)\r\n","        loss = outputs[0]\r\n","        logits = outputs[1]\r\n","            \r\n","        total_eval_loss += loss.item()\r\n","        logits = logits.detach().cpu().numpy()\r\n","        label_ids = b_labels.to('cpu').numpy()\r\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\r\n","\r\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\r\n","\r\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n","    \r\n","    validation_time = format_time(time.time() - t0)\r\n","\r\n","    training_stats.append(\r\n","        {\r\n","            'epoch': epoch_i + 1,\r\n","            'Training Loss': avg_train_loss,\r\n","            'Valid. Loss': avg_val_loss,\r\n","            'Valid. Accur.': avg_val_accuracy,\r\n","            'Training Time': training_time,\r\n","            'Validation Time': validation_time\r\n","        }\r\n","    )\r\n","\r\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["======== Epoch 1 / 5 ========\n","  Average training loss: 1.60\n","  Training epcoh took: 0:01:25\n","  Accuracy: 0.47\n","======== Epoch 2 / 5 ========\n","  Average training loss: 1.18\n","  Training epcoh took: 0:01:31\n","  Accuracy: 0.50\n","======== Epoch 3 / 5 ========\n","  Average training loss: 1.05\n","  Training epcoh took: 0:01:35\n","  Accuracy: 0.59\n","======== Epoch 4 / 5 ========\n","  Average training loss: 0.98\n","  Training epcoh took: 0:01:35\n","  Accuracy: 0.56\n","======== Epoch 5 / 5 ========\n","  Average training loss: 0.95\n","  Training epcoh took: 0:01:35\n","  Accuracy: 0.60\n","Total training took 0:08:01 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vs2Z7zvKZYGM"},"source":["### **결과**\r\n","\r\n","eng 변수에 en_data 파일 위치를 집어넣고 코드를 수행시켜 결과 출력"]},{"cell_type":"code","metadata":{"id":"oLqTkKZxJzdc","executionInfo":{"status":"ok","timestamp":1608625606031,"user_tz":-540,"elapsed":482123,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["import pandas as pd\r\n","\r\n","eng = pd.read_csv('/content/drive/MyDrive/dataset/en_data.csv')"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"wYahMmEhLaoZ","executionInfo":{"status":"ok","timestamp":1608625606033,"user_tz":-540,"elapsed":482117,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}},"outputId":"a1aed95a-7400-47c0-daa6-d3a5a92649b1"},"source":["eng.head()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>i_dialog</th>\n","      <th>i_utterance</th>\n","      <th>speaker</th>\n","      <th>utterance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Phoebe</td>\n","      <td>Alright, whadyou do with him?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Monica</td>\n","      <td>Oh! You're awake!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Joey</td>\n","      <td>Then you gotta come clean with Ma! This is not...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Mr. Tribbiani</td>\n","      <td>Yeah, but this is</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Joey</td>\n","      <td>I don't wanna hear it! Now go to my room!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          utterance\n","0   0  ...                      Alright, whadyou do with him?\n","1   1  ...                                  Oh! You're awake!\n","2   2  ...  Then you gotta come clean with Ma! This is not...\n","3   3  ...                                  Yeah, but this is\n","4   4  ...          I don't wanna hear it! Now go to my room!\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"eGstmeZZJzkv","executionInfo":{"status":"ok","timestamp":1608625606034,"user_tz":-540,"elapsed":482113,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["sentences = eng.utterance.values"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mjjs1DXTcfSW","executionInfo":{"status":"ok","timestamp":1608625606034,"user_tz":-540,"elapsed":482108,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["def test_sentences(sentences):\r\n","    model.eval()\r\n","    inputs, masks = convert_input_data(sentences)\r\n","\r\n","    b_input_ids = inputs.to(device)\r\n","    b_input_mask = masks.to(device)\r\n","            \r\n","    with torch.no_grad():     \r\n","        outputs = model(b_input_ids, \r\n","                        token_type_ids=None, \r\n","                        attention_mask=b_input_mask)\r\n","    logits = outputs[0]\r\n","    logits = logits.detach().cpu().numpy()\r\n","    return logits\r\n","\r\n","def convert_input_data(sentences):\r\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n","    input_ids = pad_sequences(input_ids, maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n","    attention_masks = []\r\n","    for seq in input_ids:\r\n","        seq_mask = [float(i>0) for i in seq]\r\n","        attention_masks.append(seq_mask)\r\n","    inputs = torch.tensor(input_ids)\r\n","    masks = torch.tensor(attention_masks)\r\n","\r\n","    return inputs, masks\r\n","\r\n","def inttolabel(idx):\r\n","    return {0:'neutral',\r\n","             1:'joy', \r\n","             2:'sadness',\r\n","             3:'fear',\r\n","             4:'anger',\r\n","             5:'surprise',\r\n","             6:'disgust',\r\n","             7:'non-neutral'}[idx]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Zg99EY1cgNL","executionInfo":{"status":"ok","timestamp":1608625626720,"user_tz":-540,"elapsed":502789,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["en_data = [['Id', 'Predicted']]\r\n","\r\n","for idx in range(len(eng['utterance'])):\r\n","  sen = eng['utterance'][idx]\r\n","  logit = test_sentences([sen])\r\n","\r\n","  en_data.append([idx, inttolabel(np.argmax(logit))])"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"9H64rLsCcgrq","executionInfo":{"status":"ok","timestamp":1608625627003,"user_tz":-540,"elapsed":503067,"user":{"displayName":"JUNGSUK LEE","photoUrl":"","userId":"16909641834700761003"}}},"source":["dataframe = pd.DataFrame(en_data)\r\n","dataframe.to_csv(\"/content/drive/MyDrive/dataset/en_result.csv\", header=False, index=False)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SKijfi5cg1U"},"source":[""],"execution_count":null,"outputs":[]}]}